{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_file_dir = Path(\"/example/path/to/blast/output/\")\n",
    "ref_path = Path(\"/example/path/to/refseq/\")\n",
    "\n",
    "genes = [os.path.basename(file).split(\"_query\")[0] for file in os.listdir(blast_file_dir) if file.endswith(\".out\")]\n",
    "print(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_off_targets(gene, blast_query_path, ref_path, armlength=20):\n",
    "    print(f\"Finding off-targets for {gene}\", flush=True)\n",
    "    file = blast_query_path / f\"{gene}_query_blast.out\"\n",
    "\n",
    "    df = pd.read_csv(file, header=None)\n",
    "\n",
    "    # Exclude lines with predicted transcripts\n",
    "    df = df.loc[~(df[1].str.contains(\"XR\") | df[1].str.contains(\"XM\"))]\n",
    "\n",
    "    # Exclude hits with less than 50% coverage and less than 80% homology\n",
    "    #df = df.loc[df[2] > 80]\n",
    "    #df = df[df[3] > 2*armlength*0.5]\n",
    "\n",
    "    # Penalise gaps in the hits\n",
    "    #df = df.loc[df[6] < armlength - 4]\n",
    "    #df = df.loc[df[7] > armlength + 5]\n",
    "\n",
    "    variants = find_variants(gene, ref_path)\n",
    "\n",
    "    # Exclude known variants \n",
    "    df = df.loc[~(df[1].isin(variants))]\n",
    "\n",
    "    df['gene'] = gene\n",
    "\n",
    "    # Write off-targets to file \n",
    "    df.to_csv(blast_query_path / f\"{gene}_off_targets.out\")\n",
    "\n",
    "\n",
    "def find_variants(gene, ref_path):\n",
    "    \"\"\"This function finds variants from the .acronymheaders.txt, selectedseqs.text and selectedheaders.txt files made by multi_padlock_design scripts\"\"\"\n",
    "    acronyms = pd.read_csv(ref_path / \"mouse.acronymheaders.txt\", header=None)\n",
    "    acronyms.columns = [\"gene_name\"]\n",
    "\n",
    "    indices = acronyms.index[acronyms.gene_name == gene].to_list()\n",
    "\n",
    "    accession_numbers = []\n",
    "    with open(ref_path / \"mouse.selectedheaders.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i in indices:\n",
    "            accession_numbers.append(lines[int(i)].strip())\n",
    "    \n",
    "    accession_numbers = format_variants(accession_numbers)\n",
    "\n",
    "    return accession_numbers\n",
    "\n",
    "def format_variants(accession_numbers):\n",
    "    # Remove the > character and take everything before the first whitespace character\n",
    "    accession_numbers = [accession.replace(\">\", \"\") for accession in accession_numbers]\n",
    "    accession_numbers = [accession.split(\" \")[0] for accession in accession_numbers]\n",
    "    return accession_numbers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in genes:\n",
    "    find_off_targets(gene, blast_file_dir, ref_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a df from all the files that end with _off_targets.out\n",
    "import natsort\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "files = glob.glob(blast_file_dir / \"*_off_targets.out\")\n",
    "# ignore the first row of each file\n",
    "df = pd.concat([pd.read_csv(file, header=0) for file in files])\n",
    "# sort df with natsort on column\n",
    "df = df.iloc[natsort.index_natsorted(df[\"0\"])]\n",
    "header = [\"query\", \"subject\", \"percentage identity\", \"length\", \"mismatches\", \"gaps\", \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\", \"qseq\", \"sseq\", \"gene\"]\n",
    "#remove the first column\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "df.columns = header\n",
    "df.sort_values(by=[\"evalue\"], inplace=True)\n",
    "df_filtered = df[df[\"evalue\"] < 1]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import config\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cached data\n",
    "cached_data = {}\n",
    "\n",
    "def loaddb(species, config):\n",
    "    \"\"\" Load formatted RefSeq header and sequence files \"\"\"\n",
    "    fastadir = (config.fastadir_mouse, config.fastadir_human)\n",
    "    fasta_filenum = (config.fasta_filenum_mouse, config.fasta_filenum_human)\n",
    "    fasta_pre_suffix = (config.fasta_pre_suffix_mouse, config.fasta_pre_suffix_human)\n",
    "\n",
    "    if species == \"mouse\":\n",
    "        s = 0\n",
    "    elif species == \"human\":\n",
    "        s = 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown species: {species}\")\n",
    "\n",
    "    if species not in cached_data:\n",
    "        if not os.path.isfile(fastadir[s] + '/' + species + '.acronymheaders.txt'):\n",
    "            print(\"Processing fasta database files..\")\n",
    "            formatrefseq.fastadb(fastadir[s], fasta_filenum[s], fasta_pre_suffix[s], species)\n",
    "        \n",
    "        with open(fastadir[s] + '/' + species + '.acronymheaders.txt', 'r') as f:\n",
    "            Acronyms = [line.rstrip('\\n') for line in f]\n",
    "        with open(fastadir[s] + '/' + species + '.selectedheaders.txt', 'r') as f:\n",
    "            Headers = [line.rstrip('\\n') for line in f]\n",
    "        with open(fastadir[s] + '/' + species + '.selectedseqs.txt', 'r') as f:\n",
    "            Seq = [line.rstrip('\\n') for line in f]\n",
    "        \n",
    "        cached_data[species] = (Acronyms, Headers, Seq)\n",
    "    return cached_data[species]\n",
    "\n",
    "def find_genes_from_variants(variants, species, config):\n",
    "    \"\"\" Find genes (acronyms) from a list of variants \"\"\"\n",
    "    Acronyms, Headers, Seq = loaddb(species, config)\n",
    "    \n",
    "    variant_to_acronym = defaultdict(list)\n",
    "    for acronym, header in zip(Acronyms, Headers):\n",
    "        gene_variant = header[1:].split('.', 1)[0]\n",
    "        variant_to_acronym[gene_variant].append(acronym)\n",
    "\n",
    "    genes = [variant_to_acronym[variant] if variant in variant_to_acronym else None for variant in variants]\n",
    "    \n",
    "    return genes\n",
    "\n",
    "# Assuming `config` is an object with the necessary attributes\n",
    "loaddb(\"mouse\", config)\n",
    "\n",
    "# Optimized DataFrame processing\n",
    "def get_genes(subject):\n",
    "    variant = subject.split('.', 1)[0]\n",
    "    return find_genes_from_variants([variant], 'mouse', config)\n",
    "\n",
    "tqdm.pandas()\n",
    "df_filtered['offtarget'] = df_filtered['subject'].progress_map(get_genes)\n",
    "df_filtered['offtarget']= df_filtered['offtarget'].apply(lambda x: x[0][0] if isinstance(x, list) and len(x) > 0 and isinstance(x[0], list) and len(x[0]) > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plot sorted evalues\n",
    "plt.figure(dpi=300)\n",
    "# Define the window size for the rolling mean\n",
    "window_size = 1  # Adjust this value based on your data\n",
    "\n",
    "df_sorted_by_evalue = df_filtered.sort_values(by='evalue')\n",
    "\n",
    "# Calculate the rolling mean of 'length'\n",
    "df_sorted_by_evalue['length_smooth'] = df_sorted_by_evalue['length'].rolling(window=window_size).mean()\n",
    "\n",
    "# Create a figure and a single subplot\n",
    "fig, ax1 = plt.subplots(dpi=300)\n",
    "\n",
    "# Plot evalue on the first y-axis\n",
    "ax1.plot(df_sorted_by_evalue[\"evalue\"].reset_index(drop=True), color='blue')\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_xlabel(\"Off-target hits\")\n",
    "ax1.set_ylabel(\"E-value\", color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis that shares the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot smoothed length on the second y-axis\n",
    "ax2.plot(df_sorted_by_evalue[\"length_smooth\"].reset_index(drop=True), color='red', alpha=0.5)\n",
    "ax2.set_ylabel(\"Length\", color='red')  # we already handled the x-label with ax1\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "plt.xlim(0, 1000)\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rolling mean of 'percentage identity'\n",
    "df_sorted_by_evalue['percentage_identity_smooth'] = df_sorted_by_evalue['percentage identity'].rolling(window=window_size).mean()\n",
    "\n",
    "# Create a figure and a single subplot\n",
    "fig, ax1 = plt.subplots(dpi=300)\n",
    "\n",
    "# Plot evalue on the first y-axis\n",
    "ax1.plot(df_sorted_by_evalue[\"evalue\"].reset_index(drop=True), color='blue')\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_xlabel(\"Off-target hits\")\n",
    "ax1.set_ylabel(\"E-value\", color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis that shares the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot smoothed percentage identity on the second y-axis\n",
    "ax2.plot(df_sorted_by_evalue[\"percentage_identity_smooth\"].reset_index(drop=True), color='green', alpha=0.5)\n",
    "ax2.set_ylabel(\"Percentage Identity\", color='green')  # we already handled the x-label with ax1\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of 'mismatches' and 'gaps', then calculate the rolling mean\n",
    "df_sorted_by_evalue['mismatches_gaps'] = df_sorted_by_evalue['mismatches'] + df_sorted_by_evalue['gaps']\n",
    "df_sorted_by_evalue['mismatches_gaps_smooth'] = df_sorted_by_evalue['mismatches_gaps'].rolling(window=window_size).mean()\n",
    "\n",
    "# Create a figure and a single subplot\n",
    "fig, ax1 = plt.subplots(dpi=300)\n",
    "\n",
    "# Plot evalue on the first y-axis\n",
    "ax1.plot(df_sorted_by_evalue[\"evalue\"].reset_index(drop=True), color='blue')\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_xlabel(\"Off-target hits\")\n",
    "ax1.set_ylabel(\"E-value\", color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Create a second y-axis that shares the same x-axis\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot smoothed mismatches+gaps on the second y-axis\n",
    "ax2.plot(df_sorted_by_evalue[\"mismatches_gaps_smooth\"].reset_index(drop=True), color='orange', alpha=0.5)\n",
    "ax2.set_ylabel(\"Mismatches+Gaps\", color='orange')  # we already handled the x-label with ax1\n",
    "ax2.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_filtered is already defined\n",
    "\n",
    "# Initialize the DataFrame\n",
    "df_padlock = pd.DataFrame(columns=[\"padlock_name\", \"gene\", \"offtarget\"])\n",
    "\n",
    "# Get unique genes\n",
    "unique_padlocks = df_filtered[\"query\"].unique()\n",
    "\n",
    "# Helper function to strip the extra list brackets from the strings\n",
    "def strip_extra_brackets(offtarget_list):\n",
    "    return [item.strip(\"['']\") for item in offtarget_list]\n",
    "\n",
    "# Populate the DataFrame\n",
    "data = []\n",
    "for padlock in tqdm(unique_padlocks):\n",
    "    gene = df_filtered[df_filtered[\"query\"] == padlock][\"gene\"].iloc[0]\n",
    "    offtargets = df_filtered[df_filtered[\"query\"] == padlock][\"offtarget\"].tolist()\n",
    "    \n",
    "    # Strip the extra brackets\n",
    "    #stripped_offtargets = strip_extra_brackets(offtargets)\n",
    "    \n",
    "    # Get unique offtargets\n",
    "    unique_offtargets = np.unique(offtargets)\n",
    "    \n",
    "    data.append({\"padlock_name\": padlock, \"gene\": gene, \"offtarget\": unique_offtargets.tolist()})\n",
    "\n",
    "df_padlock = pd.DataFrame(data)\n",
    "df_padlock\n",
    "\n",
    "# Group by gene and aggregate off-targets\n",
    "df_gene = df_padlock.groupby(\"gene\")[\"offtarget\"].apply(lambda x: np.unique(np.concatenate(x.tolist()))).reset_index()\n",
    "df_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mygene\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the MyGene client\n",
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "# Function to get the main symbols for a gene (up to 5 hits)\n",
    "def get_main_symbols(gene):\n",
    "    retries = 5\n",
    "    backoff_factor = 0.5\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            result = mg.query(gene, species='mouse', size=20)  # Change to 'human' if using human genes\n",
    "            if 'hits' in result and result['hits']:\n",
    "                return [hit.get('symbol', 'No symbol found') for hit in result['hits']]\n",
    "            return ['No symbol found']\n",
    "        except HTTPError as e:\n",
    "            if e.response.status_code == 429:\n",
    "                wait = backoff_factor * (2 ** i)  # Exponential backoff\n",
    "                print(f\"Rate limited. Retrying in {wait} seconds...\")\n",
    "                time.sleep(wait)\n",
    "            else:\n",
    "                raise e\n",
    "    return ['No symbol found']\n",
    "\n",
    "# Function to process each row\n",
    "def process_row(row):\n",
    "    gene = row.gene\n",
    "    offtarget_symbols = row.offtarget\n",
    "    \n",
    "    # Get the main symbols for the gene\n",
    "    main_symbols = get_main_symbols(gene)\n",
    "    \n",
    "    # Filter out the main symbols from the offtarget list\n",
    "    filtered_symbols = [symbol for symbol in offtarget_symbols if symbol not in main_symbols]\n",
    "    \n",
    "    if filtered_symbols:  # Only add rows where the filtered list is not empty\n",
    "        return filtered_symbols\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Perform the main symbol queries in parallel\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    filtered_offtarget = list(tqdm(executor.map(process_row, df_padlock.itertuples(index=False)), total=len(df_padlock)))\n",
    "\n",
    "# Create a new DataFrame with the filtered offtarget lists\n",
    "df_padlock_filtered = df_padlock.copy()\n",
    "df_padlock_filtered['offtarget'] = filtered_offtarget\n",
    "\n",
    "# Remove rows where offtarget is None (i.e., all genes were deleted)\n",
    "df_padlock_filtered = df_padlock_filtered[df_padlock_filtered['offtarget'].notna()]\n",
    "\n",
    "df_padlock_filtered.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mygene\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the MyGene client\n",
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "# Function to get the main symbols for a gene (up to 5 hits)\n",
    "def get_main_symbols(gene):\n",
    "    result = mg.query(gene, species='mouse', size=20)\n",
    "    if 'hits' in result and result['hits']:\n",
    "        return [hit.get('symbol', 'No symbol found') for hit in result['hits']]\n",
    "    return ['No symbol found']\n",
    "\n",
    "# Function to process each row\n",
    "def process_row(row):\n",
    "    gene = row.gene\n",
    "    offtarget_symbols = row.offtarget\n",
    "    \n",
    "    # Get the main symbols for the gene\n",
    "    main_symbols = get_main_symbols(gene)\n",
    "    \n",
    "    # Filter out the main symbols from the offtarget list\n",
    "    filtered_symbols = [symbol for symbol in offtarget_symbols if symbol not in main_symbols]\n",
    "    \n",
    "    if filtered_symbols:  # Only add rows where the filtered list is not empty\n",
    "        return filtered_symbols\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Perform the main symbol queries in parallel\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    filtered_offtarget = list(tqdm(executor.map(process_row, df_gene.itertuples(index=False)), total=len(df_gene)))\n",
    "\n",
    "# Create a new DataFrame with the filtered offtarget lists\n",
    "df_gene_filtered = df_gene.copy()\n",
    "df_gene_filtered['offtarget'] = filtered_offtarget\n",
    "\n",
    "# Remove rows where offtarget is None (i.e., all genes were deleted)\n",
    "df_gene_filtered = df_gene_filtered[df_gene_filtered['offtarget'].notna()]\n",
    "\n",
    "df_gene_filtered.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_padlock_filtered.to_csv(\"/example_path/df_padlock_filtered.csv\", index=False)\n",
    "df_gene_filtered.to_csv(\"/example_path/df_gene_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probes = pd.read_csv(\"/example/path/to/original_padlocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculating the number of padlocks per gene from all_probes\n",
    "padlocks_per_gene_all_probes = all_probes['gene_name'].value_counts()\n",
    "\n",
    "# Calculating the number of padlocks per gene from df_padlock\n",
    "padlocks_per_gene_df_padlock = df_padlock_filtered['gene'].value_counts()\n",
    "\n",
    "# Combining the two counts into one DataFrame for plotting\n",
    "genes = padlocks_per_gene_all_probes.index.union(padlocks_per_gene_df_padlock.index)\n",
    "combined_counts = pd.DataFrame({\n",
    "    'Total Padlocks': padlocks_per_gene_all_probes.reindex(genes, fill_value=0),\n",
    "    'Padlocks in df_padlock': padlocks_per_gene_df_padlock.reindex(genes, fill_value=0)\n",
    "})\n",
    "\n",
    "# Plotting the data\n",
    "fig, ax = plt.subplots(figsize=(60, 6))\n",
    "combined_counts['Total Padlocks'].plot(kind='bar', color='black', ax=ax, position=0, width=0.4)\n",
    "combined_counts['Padlocks in df_padlock'].plot(kind='bar', color='red', ax=ax, position=1, width=0.4)\n",
    "\n",
    "# Customizing the plot\n",
    "ax.set_title('Off target padlocks per Gene')\n",
    "ax.set_xlabel('Gene')\n",
    "ax.set_ylabel('Number of Padlocks')\n",
    "ax.legend(['Total Padlocks', 'Off-target Padlocks'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
